{
  "hash": "a45c94e9618fd5b894e70904bc475517",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands-on Exercise 06: Global/Local Measures of Spatial Autocorrelation\"\nauthor: \"Pan Mingwei\"\ndate: \"September 19, 2024\"\ndate-modified: \"last-modified\"\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\n# 1. Overview\n\nIn this hands-on exercise, I will learn how to compute Global Measures of Spatial Autocorrelation (GMSA) and Local Measures of Spatial Autocorrelation (LMSA) by using **spdep** package.\n\n## 1.1 What is Global Measures of Spatial Autocorrelation (GMSA)\n\nEvaluate the overall degree of spatial dependence (autocorrelation) across the entire study area.\n\n-   **Moran’s I**: A widely used global indicator that measures whether a variable is spatially clustered, dispersed, or randomly distributed.\n\n    -   **I \\> 0**: Clustered, observation tend to be similar.\n\n    -   **I \\< 0**: Dispersed, observations tend to be dissimilar.\n\n    -   **approximately zero**: observations are arranged randomly over space.\n\n-   **Geary’s C**: Similar to Moran’s I but more sensitive to local differences.\n\n    -   C \\> 1: Dispersed, observations tend to be dissimilar.\n\n    -   C \\< 1: Clustered, observations tend to be similar.\n\n    -   C = 1: Observations are arranged randomly over space.\n\nBy the end of this hands-on exercise, I will be able to :\n\n-   compute Global Spatial Autocorrelation (GSA) statistics by using appropriate functions of **spdep**package,\n\n    -   plot Moran scatterplot,\n\n    -   compute and plot spatial correlogram using appropriate function of **spdep** package.\n\n-   provide statistically correct interpretation of GSA statistics.\n\n## 1.2 What is Local Measures of Spatial Autocorrelation (LMSA)\n\nAssess the degree of spatial autocorrelation at a local, rather than global, scale to identify clusters or outliers in specific areas.\n\n-   **Local** **Moran’s I:** Measures how much a given location contributes to the overall Moran’s I, identifying local clusters and outliers.\n\n    -   **Local cluster**: Significant and **positive** if location i is associated with relatively **high values** of the surrounding locations.\n\n    -   **Local outlier**: Significant and **negative** if location i is associated with relatively **low values** in surrounding locations.\n\n-   **Getis-Ord Gi\\***:Measures local “hotspots” and “cold spots” where values are significantly higher or lower than expected.\n\n    -   **Hot spot area**: Significant and **positive** if location i is associated with relatively **high values** of the surrounding locations.\n\n    -   **Cold spot area**: Significant and **negative** if location i is associated with relatively **low values** in surrounding locations.\n\nBy the end of the hands-on, I will be able to :\n\n-   compute Local Indicator of Spatial Association (LISA) statistics for detecting clusters and outliers by using appropriate functions **spdep** package;\n\n-   compute Getis-Ord’s Gi-statistics for detecting hot spot or/and cold spot area by using appropriate functions of **spdep** package; and\n\n-   to visualise the analysis output by using **tmap** package.\n\n# 2. Getting Started\n\n## 2.1 The Analytical Question\n\nIn spatial policy, one of the main development objective of the local government and planners is to ensure equal distribution of development in the province. Our task in this study, hence, is to apply appropriate spatial statistical methods to discover if development are even distributed geographically. If the answer is **No**. Then, our next question will be “is there sign of spatial clustering?”. And, if the answer for this question is yes, then our next question will be “where are these clusters?”\n\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of [Hunan Provice](https://en.wikipedia.org/wiki/Hunan), People Republic of China.\n\n## 2.2 The Study Area and Data\n\n-   Hunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\n\n-   Hunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n## 2.3 Setting the Analytical Tools\n\n-   **sf** is use for importing and handling geospatial data in R,\n\n-   **tidyverse** is mainly use for wrangling attribute data in R,\n\n-   **spdep** will be used to compute spatial weights, global and local spatial autocorrelation statistics, and\n\n-   **tmap** will be used to prepare cartographic quality chropleth map.\n\nTo check if the packages have been installed in R and load the packages into the current R environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, spdep, tmap, tidyverse)\n```\n:::\n\n\n# 3. Load the Data into R Environment\n\n## 3.1 Import shapefile\n\nUsing `st_read()` of sf package to import Hunan shapefile into R. It will be in sf object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sf <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `/Users/mingwei/Desktop/SMU/Y3S1/IS415/xXxPMWxXx/IS415-GAA/Hands-on_Ex/Hands-on_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n## 3.2 Import CSV File\n\nUsing `read_csv()` of readr package. The output is R data frame class.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n```\n:::\n\n\n## 3.3 Performing Relational Join\n\nUsing `left_join()` of **dplyr** package to update the attribute table of hunan_sf with the attribute fields of hunan2012 dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sf <- left_join(hunan_sf,hunan2012) %>%\n  dplyr::select(1:4, 7, 15)\n```\n:::\n\n\n## 3.4 Visualising Regional Development Indicator\n\nTo prepare a basemap and a choropleth map showing the distribution of GDPPC 2021 using `qtm()` of **tmap** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nequal <- tm_shape(hunan_sf) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan_sf) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex06_files/figure-html/unnamed-chunk-5-1.png){width=1152}\n:::\n:::\n\n\n# 4. Global Measures of Spatial Autocorrelation\n\nThis section, I will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n## 4.1 Computing Contiguity Spatial Weights\n\nBefore we can compute the global spatial autocorrelation statistics, we need to **construct a spatial weights** of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\n\nIn the code chunk below, [`poly2nb()`](https://r-spatial.github.io/spdep/reference/poly2nb.html) of **spdep** package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- poly2nb(hunan_sf, \n                queen=TRUE)\nsummary(wm_q)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n```\n\n\n:::\n:::\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit(85) has 11 neighbours. There are two area units(30,65) with only one neighbours.\n\n## 4.2 Row-Standardised Weights Matrix\n\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(wm_q)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"nb\"\n```\n\n\n:::\n:::\n\n\n::: callout-note\n-   The input of [`nb2listw()`](https://r-spatial.github.io/spdep/reference/nb2listw.html) must be an object of class **nb**. The syntax of the function has two major arguments, namely style and zero.poly.\n\n-   *style* can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\n\n-   If *zero policy* is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %\\*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n:::\n\n# 5. Global Measures of Spatial Autocorrelation: Moran's I\n\nIn this section, I will learn how to perform Moran's I statistics testing by using `moran.test()` of **spdep**.\n\n## 5.1 Maron's I Test\n\nUsing `moran.test()` of **spdep**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoran.test(hunan_sf$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  hunan_sf$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n```\n\n\n:::\n:::\n\n\n::: callout-note\n-   I = 0.3, indicates **positive spatial autocorrelation**, meaning that areas with similar values of GDP per capita (either high or low) are geographically clustered together. \n:::\n",
    "supporting": [
      "Hands-on_Ex06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}